# -*- coding: utf-8 -*-
"""pix2pix_DR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14seGEyz3G76vUBmUjVsLGAZFgF5LhXJz
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import pandas as pd
import os
import numpy as np
import re
from google.colab import files

def build_generator():
    inputs = layers.Input(shape=(256, 256, 3))

    # Encoder
    x = layers.Conv2D(64, 4, strides=2, padding="same", activation="relu")(inputs)
    x = layers.Conv2D(128, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2D(256, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2D(512, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2D(512, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2D(512, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2D(512, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2D(512, 4, strides=2, padding="same", activation="relu")(x)

    # Decoder
    x = layers.Conv2DTranspose(512, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2DTranspose(512, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2DTranspose(512, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2DTranspose(512, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2DTranspose(256, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2DTranspose(128, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2DTranspose(64, 4, strides=2, padding="same", activation="relu")(x)
    outputs = layers.Conv2DTranspose(3, 4, strides=2, padding="same", activation="tanh")(x)

    return keras.Model(inputs=inputs, outputs=outputs, name="generator")

# Define the discriminator model
def build_discriminator():
    inputs = layers.Input(shape=(256, 256, 3))

    # Encoder
    x = layers.Conv2D(64, 4, strides=2, padding="same", activation="relu")(inputs)
    x = layers.Conv2D(128, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2D(256, 4, strides=2, padding="same", activation="relu")(x)
    x = layers.Conv2D(512, 4, strides=1, padding="same", activation="relu")(x)

    # Output layer
    outputs = layers.Conv2D(1, 4, strides=1, padding="same", activation="sigmoid")(x)

    return keras.Model(inputs=inputs, outputs=outputs, name="discriminator")

# Define the generator and discriminator models
generator = build_generator()
discriminator = build_discriminator()

# Define the loss functions
bce_loss = keras.losses.BinaryCrossentropy(from_logits=False)

from google.colab import drive
drive.mount('/content/drive')

# replace 'data_folder' with the name of the folder that you created in Google Drive
data_folder = "/content/drive/My Drive/<name_of_folder>"

# now you can access files in this folder as you would in your local file system

# Load the dataset
dataset = pd.read_


# Preprocess the images
def preprocess_image(image):
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, [256, 256])
    image = tf.cast(image, tf.float32) / 127.5 - 1.0
    return image

# Create a function to load and preprocess a pair of images
def load_image(image_file):
    image = tf.io.read_file(image_file)
    input_image = preprocess_image(image)
    output_image = preprocess_image(image)
    return input_image, output_image

# Apply the load_image function to each image in the dataset
dataset = dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)
dataset = dataset.batch(1)

# Define the optimizers
generator_optimizer = keras.optimizers.Adam(2e-4, beta_1=0.5)
discriminator_optimizer = keras.optimizers.Adam(2e-4, beta_1=0.5)

# Define the training loop
@tf.function
def train_step(inputs, outputs):
    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        # Generate fake images from the generator
        generated_images = generator(inputs, training=True)

        # Calculate the discriminator loss
        real_output = discriminator(outputs, training=True)
        fake_output = discriminator(generated_images, training=True)
        disc_loss = bce_loss(tf.ones_like(real_output), real_output) + bce_loss(tf.zeros_like(fake_output), fake_output)

        # Calculate the generator loss
        gen_loss = mse_loss(outputs, generated_images) + 100 * bce_loss(tf.ones_like(fake_output), fake_output)

    # Calculate the gradients and apply them to the optimizer
    generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)
    discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)
    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))

# Train the model
for epoch in range(59):
    for inputs, outputs in dataset:
        train_step(inputs, outputs)

# Generate fake images using the generator
for inputs, _ in dataset.take(1):
    generated_images = generator(inputs, training=False)

# Plot the results
import matplotlib.pyplot as plt
fig, ax = plt.subplots(1, 2, figsize=(10, 5))
ax[0].imshow(inputs[0] * 0.5 + 0.5)
ax[0].set_title("Input Image")
ax[1].imshow(generated_images[0] * 0.5 + 0.5)
ax[1].set_title("Generated Image")
plt.show()

